{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from EMAWorkbench import Policy\n",
    "from EMAWorkbench.em_framework import sample_uncertainties\n",
    "from EMAWorkbench import SequentialEvaluator, ema_logging, save_results, load_results\n",
    "\n",
    "\n",
    "def evaluation(model, problem, random_seed, steps, policy_path, result_path, real_num=False):\n",
    "    the_model, _ = model(problem=problem, random_seed=random_seed)\n",
    "\n",
    "    ea_policies = pd.read_csv(policy_path)\n",
    "    policies = []\n",
    "    for index, row in ea_policies.iterrows():\n",
    "        if real_num:\n",
    "            policy = Policy(str(index), **{str(i):row[str(i)] for i in range(steps)})\n",
    "        else:\n",
    "            policy = Policy(str(index), **{str(i):int(row[str(i)]) for i in range(steps)})\n",
    "        policies.append(policy)\n",
    "        \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "    \n",
    "    i = 0\n",
    "    for policy in policies:\n",
    "        with SequentialEvaluator(the_model) as evaluator:\n",
    "            results = evaluator.perform_experiments(policies=policy)\n",
    "\n",
    "        save_results(results, result_path+f'{current_time}_{i}.tar.gz')\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_evaluation(model, problem, random_seed, steps, scenarios_num, \n",
    "                          scenario_path, policy_path, result_path, real_num=False):\n",
    "    the_model, _ = model(problem=problem, random_seed=random_seed)\n",
    "    \n",
    "    evaluation_df_read = pd.read_csv(scenario_path)\n",
    "    evaluation_scenarios_designs = list(evaluation_df_read.to_records(index=False))\n",
    "    evaluation_scenarios = sample_uncertainties(the_model, scenarios_num)\n",
    "    evaluation_scenarios.designs = evaluation_scenarios_designs\n",
    "\n",
    "    ea_policies = pd.read_csv(policy_path)\n",
    "    policies = []\n",
    "    for index, row in ea_policies.iterrows():\n",
    "        if real_num:\n",
    "            policy = Policy(str(index), **{str(i):row[str(i)] for i in range(steps)})\n",
    "        else:\n",
    "            policy = Policy(str(index), **{str(i):int(row[str(i)]) for i in range(steps)})\n",
    "        policies.append(policy)\n",
    "        \n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    current_time = datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "    \n",
    "    if not os.path.exists(result_path):\n",
    "        os.makedirs(result_path)\n",
    "\n",
    "    i = 0\n",
    "    for policy in policies:\n",
    "        with SequentialEvaluator(the_model) as evaluator:\n",
    "            results = evaluator.perform_experiments(scenarios=evaluation_scenarios, policies=policy)\n",
    "\n",
    "        save_results(results, result_path+f'{current_time}_{i}.tar.gz')\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discrete Dam Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'discrete_2_1274569960-17-11-2022-06-17_convergence.csv',\n",
       " 'discrete_2_1274569960-17-11-2022-06-17_policy.csv',\n",
       " 'discrete_2_1350287007-17-11-2022-06-27_convergence.csv',\n",
       " 'discrete_2_1350287007-17-11-2022-06-27_policy.csv',\n",
       " 'discrete_2_1883682950-17-11-2022-06-34_convergence.csv',\n",
       " 'discrete_2_1883682950-17-11-2022-06-34_policy.csv',\n",
       " 'discrete_2_1926216712-17-11-2022-06-10_convergence.csv',\n",
       " 'discrete_2_1926216712-17-11-2022-06-10_policy.csv',\n",
       " 'discrete_2_2097286424-17-11-2022-06-19_convergence.csv',\n",
       " 'discrete_2_2097286424-17-11-2022-06-19_policy.csv',\n",
       " 'discrete_2_2523200676-17-11-2022-06-15_convergence.csv',\n",
       " 'discrete_2_2523200676-17-11-2022-06-15_policy.csv',\n",
       " 'discrete_2_2861224539-17-11-2022-06-25_convergence.csv',\n",
       " 'discrete_2_2861224539-17-11-2022-06-25_policy.csv',\n",
       " 'discrete_2_3087161096-17-11-2022-06-12_convergence.csv',\n",
       " 'discrete_2_3087161096-17-11-2022-06-12_policy.csv',\n",
       " 'discrete_2_3186775264-17-11-2022-06-04_convergence.csv',\n",
       " 'discrete_2_3186775264-17-11-2022-06-04_policy.csv',\n",
       " 'discrete_2_3624030427-17-11-2022-06-30_convergence.csv',\n",
       " 'discrete_2_3624030427-17-11-2022-06-30_policy.csv',\n",
       " 'discrete_2_3668976038-17-11-2022-06-38_convergence.csv',\n",
       " 'discrete_2_3668976038-17-11-2022-06-38_policy.csv',\n",
       " 'discrete_2_3690172787-17-11-2022-06-06_convergence.csv',\n",
       " 'discrete_2_3690172787-17-11-2022-06-06_policy.csv',\n",
       " 'discrete_2_3885705317-17-11-2022-06-21_convergence.csv',\n",
       " 'discrete_2_3885705317-17-11-2022-06-21_policy.csv',\n",
       " 'discrete_2_462638671-17-11-2022-06-08_convergence.csv',\n",
       " 'discrete_2_462638671-17-11-2022-06-08_policy.csv',\n",
       " 'discrete_2_562732020-17-11-2022-06-23_convergence.csv',\n",
       " 'discrete_2_562732020-17-11-2022-06-23_policy.csv',\n",
       " 'discrete_2_617160326-17-11-2022-06-36_convergence.csv',\n",
       " 'discrete_2_617160326-17-11-2022-06-36_policy.csv',\n",
       " 'discrete_2_674137616-17-11-2022-06-28_convergence.csv',\n",
       " 'discrete_2_674137616-17-11-2022-06-28_policy.csv',\n",
       " 'discrete_2_703574460-17-11-2022-06-32_convergence.csv',\n",
       " 'discrete_2_703574460-17-11-2022-06-32_policy.csv',\n",
       " 'discrete_2_956500800-17-11-2022-06-13_convergence.csv',\n",
       " 'discrete_2_956500800-17-11-2022-06-13_policy.csv',\n",
       " 'discrete_2_96930842-17-11-2022-06-40_convergence.csv',\n",
       " 'discrete_2_96930842-17-11-2022-06-40_policy.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.ema_dam import dam_problem\n",
    "from utils.ea.create_models import create_dam_discrete_training\n",
    "\n",
    "policy_path = '../../results/ea_dam_1/'\n",
    "files=sorted(os.listdir(policy_path))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1274569960/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1274569960/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1274569960/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1274569960/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1274569960/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1350287007/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1350287007/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1350287007/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1350287007/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1350287007/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1883682950/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1883682950/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1883682950/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1883682950/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1883682950/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1926216712/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1926216712/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1926216712/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1926216712/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_1926216712/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2097286424/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2097286424/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2097286424/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2097286424/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2097286424/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2523200676/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2523200676/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2523200676/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2523200676/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2523200676/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2861224539/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2861224539/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2861224539/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2861224539/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_2861224539/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3087161096/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3087161096/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3087161096/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3087161096/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3087161096/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3186775264/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3186775264/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3186775264/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3186775264/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3186775264/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3624030427/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3624030427/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3624030427/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3624030427/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3624030427/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3668976038/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3668976038/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3668976038/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3668976038/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3668976038/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3690172787/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3690172787/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3690172787/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3690172787/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3690172787/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3885705317/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3885705317/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3885705317/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_3885705317/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_462638671/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_462638671/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_462638671/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_462638671/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_462638671/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_562732020/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_562732020/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_562732020/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_562732020/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_562732020/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_617160326/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_617160326/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_617160326/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_617160326/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_617160326/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_674137616/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_674137616/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_674137616/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_674137616/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_674137616/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_703574460/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_703574460/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_703574460/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_703574460/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_703574460/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_956500800/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_956500800/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_956500800/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_956500800/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_956500800/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_discrete_performance_2/ea_96930842/13-03-2023-08-54_5.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(files), 2):\n",
    "    seed = re.split(\"_|-\", files[i])[2]\n",
    "    evaluation(model=create_dam_discrete_training, problem=dam_problem, random_seed=1793476144, steps=100,\n",
    "               policy_path=f'{policy_path}{files[i]}',\n",
    "               result_path=f'../../results/dam_discrete_performance_2/ea_{seed}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Dam Problem (deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '10th_20_1274569960-20-11-2022-06-10_convergence.csv',\n",
       " '10th_20_1274569960-20-11-2022-06-10_policy.csv',\n",
       " '10th_20_1350287007-20-11-2022-20-56_convergence.csv',\n",
       " '10th_20_1350287007-20-11-2022-20-56_policy.csv',\n",
       " '10th_20_1883682950-21-11-2022-08-45_convergence.csv',\n",
       " '10th_20_1883682950-21-11-2022-08-45_policy.csv',\n",
       " '10th_20_1926216712-19-11-2022-18-23_convergence.csv',\n",
       " '10th_20_1926216712-19-11-2022-18-23_policy.csv',\n",
       " '10th_20_2097286424-20-11-2022-09-07_convergence.csv',\n",
       " '10th_20_2097286424-20-11-2022-09-07_policy.csv',\n",
       " '10th_20_2523200676-20-11-2022-03-13_convergence.csv',\n",
       " '10th_20_2523200676-20-11-2022-03-13_policy.csv',\n",
       " '10th_20_2861224539-20-11-2022-17-58_convergence.csv',\n",
       " '10th_20_2861224539-20-11-2022-17-58_policy.csv',\n",
       " '10th_20_3087161096-19-11-2022-21-20_convergence.csv',\n",
       " '10th_20_3087161096-19-11-2022-21-20_policy.csv',\n",
       " '10th_20_3186775264-19-11-2022-05-42_convergence.csv',\n",
       " '10th_20_3186775264-19-11-2022-05-42_policy.csv',\n",
       " '10th_20_3186775264-19-11-2022-09-32_convergence.csv',\n",
       " '10th_20_3186775264-19-11-2022-09-32_policy.csv',\n",
       " '10th_20_3624030427-21-11-2022-02-51_convergence.csv',\n",
       " '10th_20_3624030427-21-11-2022-02-51_policy.csv',\n",
       " '10th_20_3668976038-21-11-2022-14-40_convergence.csv',\n",
       " '10th_20_3668976038-21-11-2022-14-40_policy.csv',\n",
       " '10th_20_3690172787-19-11-2022-12-29_convergence.csv',\n",
       " '10th_20_3690172787-19-11-2022-12-29_policy.csv',\n",
       " '10th_20_3885705317-20-11-2022-12-04_convergence.csv',\n",
       " '10th_20_3885705317-20-11-2022-12-04_policy.csv',\n",
       " '10th_20_462638671-19-11-2022-15-26_convergence.csv',\n",
       " '10th_20_462638671-19-11-2022-15-26_policy.csv',\n",
       " '10th_20_562732020-20-11-2022-15-01_convergence.csv',\n",
       " '10th_20_562732020-20-11-2022-15-01_policy.csv',\n",
       " '10th_20_617160326-21-11-2022-11-42_convergence.csv',\n",
       " '10th_20_617160326-21-11-2022-11-42_policy.csv',\n",
       " '10th_20_674137616-20-11-2022-23-53_convergence.csv',\n",
       " '10th_20_674137616-20-11-2022-23-53_policy.csv',\n",
       " '10th_20_703574460-21-11-2022-05-48_convergence.csv',\n",
       " '10th_20_703574460-21-11-2022-05-48_policy.csv',\n",
       " '10th_20_956500800-20-11-2022-00-17_convergence.csv',\n",
       " '10th_20_956500800-20-11-2022-00-17_policy.csv',\n",
       " '10th_20_96930842-21-11-2022-17-38_convergence.csv',\n",
       " '10th_20_96930842-21-11-2022-17-38_policy.csv',\n",
       " 'avg_20_1274569960-22-11-2022-17-08_convergence.csv',\n",
       " 'avg_20_1274569960-22-11-2022-17-08_policy.csv',\n",
       " 'avg_20_1350287007-23-11-2022-07-50_convergence.csv',\n",
       " 'avg_20_1350287007-23-11-2022-07-50_policy.csv',\n",
       " 'avg_20_1883682950-23-11-2022-19-36_convergence.csv',\n",
       " 'avg_20_1883682950-23-11-2022-19-36_policy.csv',\n",
       " 'avg_20_1926216712-22-11-2022-05-24_convergence.csv',\n",
       " 'avg_20_1926216712-22-11-2022-05-24_policy.csv',\n",
       " 'avg_20_2097286424-22-11-2022-20-04_convergence.csv',\n",
       " 'avg_20_2097286424-22-11-2022-20-04_policy.csv',\n",
       " 'avg_20_2523200676-22-11-2022-14-12_convergence.csv',\n",
       " 'avg_20_2523200676-22-11-2022-14-12_policy.csv',\n",
       " 'avg_20_2861224539-23-11-2022-04-53_convergence.csv',\n",
       " 'avg_20_2861224539-23-11-2022-04-53_policy.csv',\n",
       " 'avg_20_3087161096-22-11-2022-08-20_convergence.csv',\n",
       " 'avg_20_3087161096-22-11-2022-08-20_policy.csv',\n",
       " 'avg_20_3186775264-21-11-2022-20-35_convergence.csv',\n",
       " 'avg_20_3186775264-21-11-2022-20-35_policy.csv',\n",
       " 'avg_20_3624030427-23-11-2022-13-43_convergence.csv',\n",
       " 'avg_20_3624030427-23-11-2022-13-43_policy.csv',\n",
       " 'avg_20_3668976038-24-11-2022-01-27_convergence.csv',\n",
       " 'avg_20_3668976038-24-11-2022-01-27_policy.csv',\n",
       " 'avg_20_3690172787-21-11-2022-23-31_convergence.csv',\n",
       " 'avg_20_3690172787-21-11-2022-23-31_policy.csv',\n",
       " 'avg_20_3885705317-22-11-2022-23-00_convergence.csv',\n",
       " 'avg_20_3885705317-22-11-2022-23-00_policy.csv',\n",
       " 'avg_20_462638671-22-11-2022-02-27_convergence.csv',\n",
       " 'avg_20_462638671-22-11-2022-02-27_policy.csv',\n",
       " 'avg_20_562732020-23-11-2022-01-57_convergence.csv',\n",
       " 'avg_20_562732020-23-11-2022-01-57_policy.csv',\n",
       " 'avg_20_617160326-23-11-2022-22-31_convergence.csv',\n",
       " 'avg_20_617160326-23-11-2022-22-31_policy.csv',\n",
       " 'avg_20_674137616-23-11-2022-10-47_convergence.csv',\n",
       " 'avg_20_674137616-23-11-2022-10-47_policy.csv',\n",
       " 'avg_20_703574460-23-11-2022-16-40_convergence.csv',\n",
       " 'avg_20_703574460-23-11-2022-16-40_policy.csv',\n",
       " 'avg_20_956500800-22-11-2022-11-16_convergence.csv',\n",
       " 'avg_20_956500800-22-11-2022-11-16_policy.csv',\n",
       " 'avg_20_96930842-24-11-2022-04-23_convergence.csv',\n",
       " 'avg_20_96930842-24-11-2022-04-23_policy.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.ema_dam_uncertain import dam_uncertain_problem\n",
    "from utils.ea.create_models import create_dam_deep_training\n",
    "\n",
    "\n",
    "policy_path = '../../results/ea_dam_deep_1/'\n",
    "files=sorted(os.listdir(policy_path))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1274569960/13-03-2023-08-59_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1350287007/13-03-2023-09-01_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1883682950/13-03-2023-09-02_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_1926216712/13-03-2023-09-04_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2097286424/13-03-2023-09-06_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2523200676/13-03-2023-09-09_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_2861224539/13-03-2023-09-11_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3087161096/13-03-2023-09-13_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_26.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-15_27.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3186775264/13-03-2023-09-18_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3624030427/13-03-2023-09-20_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3668976038/13-03-2023-09-24_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3690172787/13-03-2023-09-25_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_3885705317/13-03-2023-09-27_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_462638671/13-03-2023-09-29_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_562732020/13-03-2023-09-32_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_617160326/13-03-2023-09-34_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_674137616/13-03-2023-09-36_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_703574460/13-03-2023-09-37_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_956500800/13-03-2023-09-39_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_10th_96930842/13-03-2023-09-42_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1274569960/13-03-2023-09-44_26.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1350287007/13-03-2023-09-47_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1883682950/13-03-2023-09-50_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_1926216712/13-03-2023-09-53_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2097286424/13-03-2023-09-56_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2523200676/13-03-2023-09-59_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_2861224539/13-03-2023-10-02_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3087161096/13-03-2023-10-05_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3186775264/13-03-2023-10-08_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3624030427/13-03-2023-10-10_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_26.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_27.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3668976038/13-03-2023-10-13_28.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3690172787/13-03-2023-10-17_26.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_26.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_27.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_28.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_29.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_30.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_3885705317/13-03-2023-10-20_31.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_462638671/13-03-2023-10-25_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_562732020/13-03-2023-10-28_25.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_617160326/13-03-2023-10-31_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_674137616/13-03-2023-12-41_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_703574460/13-03-2023-16-43_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_956500800/13-03-2023-16-46_24.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_0.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_1.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_2.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_3.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_4.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_5.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_6.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_7.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_8.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_9.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_10.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_11.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_12.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_13.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_14.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_15.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_16.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_17.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_18.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_19.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_20.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_21.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_22.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_23.tar.gz\n",
      "[MainProcess/INFO] performing 1000 scenarios * 1 policies * 1 model(s) = 1000 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] 200 cases completed\n",
      "[MainProcess/INFO] 300 cases completed\n",
      "[MainProcess/INFO] 400 cases completed\n",
      "[MainProcess/INFO] 500 cases completed\n",
      "[MainProcess/INFO] 600 cases completed\n",
      "[MainProcess/INFO] 700 cases completed\n",
      "[MainProcess/INFO] 800 cases completed\n",
      "[MainProcess/INFO] 900 cases completed\n",
      "[MainProcess/INFO] 1000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/dam_deep_performance_2/ea_avg_96930842/13-03-2023-16-49_24.tar.gz\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(files), 2):\n",
    "    tmp = re.split(\"_|-\", files[i])\n",
    "    r_metric = tmp[0]\n",
    "    seed = tmp[2]\n",
    "    robustness_evaluation(model=create_dam_deep_training, problem=dam_uncertain_problem, \n",
    "                          random_seed=1793476144, steps=100, scenarios_num=1000,\n",
    "                          scenario_path=\"../../results/dam_scenarios/evaluation_scenarios.csv\",\n",
    "                          policy_path=f'{policy_path}{files[i]}',\n",
    "                          result_path=f'../../results/dam_deep_performance_2/ea_{r_metric}_{seed}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discrete Lake Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['discrete_200_1274569960-29-11-2022-00-06_convergence.csv',\n",
       " 'discrete_200_1274569960-29-11-2022-00-06_policy.csv',\n",
       " 'discrete_200_1350287007-29-11-2022-11-08_convergence.csv',\n",
       " 'discrete_200_1350287007-29-11-2022-11-08_policy.csv',\n",
       " 'discrete_200_1883682950-29-11-2022-19-25_convergence.csv',\n",
       " 'discrete_200_1883682950-29-11-2022-19-25_policy.csv',\n",
       " 'discrete_200_1926216712-28-11-2022-16-20_convergence.csv',\n",
       " 'discrete_200_1926216712-28-11-2022-16-20_policy.csv',\n",
       " 'discrete_200_2097286424-29-11-2022-02-05_convergence.csv',\n",
       " 'discrete_200_2097286424-29-11-2022-02-05_policy.csv',\n",
       " 'discrete_200_2523200676-28-11-2022-22-10_convergence.csv',\n",
       " 'discrete_200_2523200676-28-11-2022-22-10_policy.csv',\n",
       " 'discrete_200_2861224539-29-11-2022-08-52_convergence.csv',\n",
       " 'discrete_200_2861224539-29-11-2022-08-52_policy.csv',\n",
       " 'discrete_200_3087161096-28-11-2022-18-16_convergence.csv',\n",
       " 'discrete_200_3087161096-28-11-2022-18-16_policy.csv',\n",
       " 'discrete_200_3186775264-28-11-2022-10-32_convergence.csv',\n",
       " 'discrete_200_3186775264-28-11-2022-10-32_policy.csv',\n",
       " 'discrete_200_3624030427-29-11-2022-15-18_convergence.csv',\n",
       " 'discrete_200_3624030427-29-11-2022-15-18_policy.csv',\n",
       " 'discrete_200_3668976038-29-11-2022-23-33_convergence.csv',\n",
       " 'discrete_200_3668976038-29-11-2022-23-33_policy.csv',\n",
       " 'discrete_200_3690172787-28-11-2022-12-27_convergence.csv',\n",
       " 'discrete_200_3690172787-28-11-2022-12-27_policy.csv',\n",
       " 'discrete_200_3885705317-29-11-2022-04-22_convergence.csv',\n",
       " 'discrete_200_3885705317-29-11-2022-04-22_policy.csv',\n",
       " 'discrete_200_462638671-28-11-2022-14-24_convergence.csv',\n",
       " 'discrete_200_462638671-28-11-2022-14-24_policy.csv',\n",
       " 'discrete_200_562732020-29-11-2022-06-36_convergence.csv',\n",
       " 'discrete_200_562732020-29-11-2022-06-36_policy.csv',\n",
       " 'discrete_200_617160326-29-11-2022-21-30_convergence.csv',\n",
       " 'discrete_200_617160326-29-11-2022-21-30_policy.csv',\n",
       " 'discrete_200_674137616-29-11-2022-13-14_convergence.csv',\n",
       " 'discrete_200_674137616-29-11-2022-13-14_policy.csv',\n",
       " 'discrete_200_703574460-29-11-2022-17-21_convergence.csv',\n",
       " 'discrete_200_703574460-29-11-2022-17-21_policy.csv',\n",
       " 'discrete_200_956500800-28-11-2022-20-13_convergence.csv',\n",
       " 'discrete_200_956500800-28-11-2022-20-13_policy.csv',\n",
       " 'discrete_200_96930842-30-11-2022-01-36_convergence.csv',\n",
       " 'discrete_200_96930842-30-11-2022-01-36_policy.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.ema_lake import lake_problem\n",
    "from utils.ea.create_models import create_lake_discrete_training\n",
    "\n",
    "policy_path = '../../results/ea_lake_1/'\n",
    "files=sorted(os.listdir(policy_path))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_5.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_6.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_7.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_8.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_9.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_10.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_11.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_12.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_13.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_14.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_15.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_16.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_17.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_18.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_19.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_20.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_21.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_22.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_23.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_24.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_25.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_26.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_27.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_28.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_29.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_30.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_31.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_32.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_33.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_34.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_35.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_36.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_37.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_38.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_39.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_40.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_41.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_42.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_43.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_44.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_45.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_46.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_47.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_48.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_49.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_50.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_51.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_52.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_53.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_54.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_55.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_56.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_57.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_58.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_59.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_60.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_61.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_62.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_63.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1274569960/13-03-2023-23-01_64.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_5.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_6.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_7.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_8.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_9.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_10.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_11.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_12.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_13.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_14.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_15.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_16.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_17.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_18.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_19.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_20.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_21.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_22.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_23.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_24.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_25.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_26.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_27.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_28.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_29.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_30.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_31.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_32.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_33.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_34.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_35.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_36.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_37.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_38.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_39.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_40.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_41.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_42.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_43.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_44.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_45.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_46.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_47.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_48.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_49.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_50.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_51.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_52.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_53.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_54.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_55.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_56.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_57.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_58.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_59.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_60.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_61.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_62.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_63.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_64.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_65.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_66.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_67.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_68.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1350287007/13-03-2023-23-01_69.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_0.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_1.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_2.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_3.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_4.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_5.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_6.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_7.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_8.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_9.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_10.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_11.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_12.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_13.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_14.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_15.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_16.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_17.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_18.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_19.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_20.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_21.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_22.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_23.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_24.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_25.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_26.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_27.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_28.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_29.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_30.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_31.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_32.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_33.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_34.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_35.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_36.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_37.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_38.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_39.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_40.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_41.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_42.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_43.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_44.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_45.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_46.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_47.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_48.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_49.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_50.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_51.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_52.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_53.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_54.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_55.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_56.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to /Users/zppei/Documents/PhD-Project/code/Evolutionary/results/lake_discrete_performance_2/ea_1883682950/13-03-2023-23-01_57.tar.gz\n",
      "[MainProcess/INFO] performing 1 scenarios * 1 policies * 1 model(s) = 1 experiments\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "/Users/zppei/Documents/PhD-Project/code/Evolutionary/EMAWorkbench/em_framework/callbacks.py:191: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[name] = pd.Series(dtype=dtype)\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] experiments finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(files), 2):\n",
    "    seed = re.split(\"_|-\", files[i])[2]\n",
    "    evaluation(model=create_lake_discrete_training, problem=lake_problem, random_seed=1793476144, steps=99,\n",
    "               policy_path=f'{policy_path}{files[i]}',\n",
    "               result_path=f'../../results/lake_discrete_performance_2/ea_{seed}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Lake Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.ema_lake_uncertain import lake_uncertain_problem\n",
    "from utils.ea.create_models import create_lake_deep_training\n",
    "\n",
    "\n",
    "policy_path = '../../results/ea_lake_robust_1/'\n",
    "files=sorted(os.listdir(policy_path))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1, len(files), 2):\n",
    "    tmp = re.split(\"_|-\", files[i])\n",
    "    r_metric = tmp[0]\n",
    "    seed = tmp[2]\n",
    "    robustness_evaluation(model=create_lake_deep_training, problem=lake_uncertain_problem, \n",
    "                          random_seed=1793476144, steps=99, scenarios_num=1000,\n",
    "                          scenario_path=\"../../results/lake_scenarios/evaluation_scenarios.csv\",\n",
    "                          policy_path=f'{policy_path}{files[i]}',\n",
    "                          result_path=f'../../results/lake_robust_performance_2/ea_{r_metric}_{seed}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
